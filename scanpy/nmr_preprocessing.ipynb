{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMR preprocessing with adaptive QC thresholds (Scanpy)\n",
    "\n",
    "This notebook loads CellBender-filtered files per region, merges replicates 1 and 2, applies QC with histogram/KDE-based adaptive threshold suggestions (from scanpy/find_means.py), and saves preprocessed AnnData objects. Raw counts are stored in `adata.layers['counts']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure local module is importable\n",
    "project_root = Path().resolve()\n",
    "module_path = project_root / 'scanpy'\n",
    "if str(module_path) not in sys.path:\n",
    "    sys.path.insert(0, str(module_path))\n",
    "from find_means import (\n",
    "    suggest_thresholds_for_obs,\n",
    "    apply_threshold_to_obs_metric,\n",
    "    interactive_select_threshold,\n",
    ")\n",
    "\n",
    "sc.settings.verbosity = 3\n",
    "sc.set_figure_params(figsize=(6, 5), dpi=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input paths and region/replicate mapping\n",
    "Assumes CellBender-filtered HDF5 files are available on a Windows path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows path containing the filtered CellBender outputs\n",
    "cellbender_dir = r'C:\\Users\\Antonio\\Documents\\Maestria\\Semestre 5\\Estancia\\Datos transcripcion NMR\\Siguiendo word\\RNA NMR Single cells\\cellbender\\clean_data\\'\n",
    "\n",
    "files = {\n",
    "    'NMR1': 'NMR1_cerebral_cortex_denoised_filtered.h5',\n",
    "    'NMR2': 'NMR2_cerebral_cortex_denoised_filtered.h5',\n",
    "    'NMR3': 'NMR3_hippocampus_denoised_filtered.h5',\n",
    "    'NMR4': 'NMR4_hippocampus_denoised_filtered.h5',\n",
    "    'NMR5': 'NMR5_midbrain_denoised_filtered.h5',\n",
    "    'NMR6': 'NMR6_midbrain_denoised_filtered.h5',\n",
    "}\n",
    "\n",
    "# Define region groupings and replicates to merge\n",
    "regions = {\n",
    "    'cerebral_cortex': ['NMR1', 'NMR2'],\n",
    "    'hippocampus': ['NMR3', 'NMR4'],\n",
    "    'midbrain': ['NMR5', 'NMR6'],\n",
    "}\n",
    "\n",
    "def resolve_path(fname):\n",
    "    p = os.path.join(cellbender_dir, fname)\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(p)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cellbender_h5(path):\n",
    "    \"\"\"\n",
    "    Reads a CellBender output HDF5. Many CellBender outputs are 10x-like h5s\n",
    "    compatible with sc.read_10x_h5. If this fails, adjust accordingly to the\n",
    "    specific file structure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        adata = sc.read_10x_h5(path)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f'Failed to read {path} as 10x h5: {e}')\n",
    "    # Ensure unique variable names\n",
    "    adata.var_names_make_unique()\n",
    "    return adata\n",
    "\n",
    "def annotate_basic_qc(adata: ad.AnnData, mito_prefixes=(\"mt-\", \"MT-\", \"Mt-\")):\n",
    "    # store raw counts in layer 'counts'\n",
    "    if adata.layers.get('counts', None) is None:\n",
    "        adata.layers['counts'] = adata.X.copy()\n",
    "    # mitochondrial percentage\n",
    "    mito_genes = adata.var_names.str.startswith(mito_prefixes).to_numpy()\n",
    "    # Compute QC metrics\n",
    "    sc.pp.calculate_qc_metrics(adata, qc_vars=[pd.Index(adata.var_names[mito_genes]).tolist()],\n",
    "                               percent_top=None, log1p=False, inplace=True)\n",
    "    # Standardize naming: pct_counts_mt\n",
    "    if 'pct_counts_in_set1' in adata.obs:\n",
    "        adata.obs.rename(columns={'pct_counts_in_set1': 'pct_counts_mt'}, inplace=True)\n",
    "    # Fallback if above not created\n",
    "    if 'pct_counts_mt' not in adata.obs:\n",
    "        # manual compute\n",
    "        if mito_genes.sum() > 0:\n",
    "            mt_counts = adata[:, mito_genes].X\n",
    "            if hasattr(mt_counts, 'toarray'):\n",
    "                mt_counts = mt_counts.toarray()\n",
    "            total = adata.X\n",
    "            if hasattr(total, 'toarray'):\n",
    "                total = total.toarray()\n",
    "            mt_pct = 100.0 * (mt_counts.sum(axis=1).A1 if hasattr(mt_counts, 'A1') else mt_counts.sum(axis=1)) / \\n",
    "                    (total.sum(axis=1).A1 if hasattr(total, 'A1') else total.sum(axis=1))\n",
    "            adata.obs['pct_counts_mt'] = mt_pct\n",
    "        else:\n",
    "            adata.obs['pct_counts_mt'] = 0.0\n",
    "    return adata\n",
    "\n",
    "def add_region_replicate_metadata(adata: ad.AnnData, region: str, replicate: str) -> ad.AnnData:\n",
    "    adata.obs['region'] = region\n",
    "    adata.obs['replicate'] = replicate\n",
    "    return adata\n",
    "\n",
    "def preprocess_one(adata: ad.AnnData, region: str) -> ad.AnnData:\n",
    "    # Example adaptive threshold suggestions for QC\n",
    "    # total_counts: typically log1p transform and choose a floor (>=)\n",
    "    out_tc = suggest_thresholds_for_obs(adata, 'total_counts', transform='log1p', show=True,\n",
    "                                        save=f'scanpy/figures/{region}_total_counts_thresholds.png')\n",
    "    thr_tc = interactive_select_threshold(out_tc['thresholds'])\n",
    "    if thr_tc is not None:\n",
    "        apply_threshold_to_obs_metric(adata, 'total_counts', thr_tc, direction='>=',\n",
    "                                      key_added='qc_total_counts_ok', original_scale=out_tc['original_scale'])\n",
    "    else:\n",
    "        adata.obs['qc_total_counts_ok'] = True\n",
    "\n",
    "    # n_genes_by_counts: also often log1p with a floor\n",
    "    if 'n_genes_by_counts' not in adata.obs:\n",
    "        # Ensure metric is available\n",
    "        sc.pp.calculate_qc_metrics(adata, inplace=True)\n",
    "    out_ng = suggest_thresholds_for_obs(adata, 'n_genes_by_counts', transform='log1p', show=True,\n",
    "                                       save=f'scanpy/figures/{region}_n_genes_by_counts_thresholds.png')\n",
    "    thr_ng = interactive_select_threshold(out_ng['thresholds'])\n",
    "    if thr_ng is not None:\n",
    "        apply_threshold_to_obs_metric(adata, 'n_genes_by_counts', thr_ng, direction='>=',\n",
    "                                      key_added='qc_ngenes_ok', original_scale=out_ng['original_scale'])\n",
    "    else:\n",
    "        adata.obs['qc_ngenes_ok'] = True\n",
    "\n",
    "    # pct_counts_mt: typically cap high-mito cells (<=) in percent units\n",
    "    out_mt = suggest_thresholds_for_obs(adata, 'pct_counts_mt', transform='none', show=True,\n",
    "                                      save=f'scanpy/figures/{region}_pct_counts_mt_thresholds.png')\n",
    "    thr_mt = interactive_select_threshold(out_mt['thresholds'])\n",
    "    if thr_mt is not None:\n",
    "        apply_threshold_to_obs_metric(adata, 'pct_counts_mt', thr_mt, direction='<=',\n",
    "                                      key_added='qc_mito_ok', original_scale=out_mt['original_scale'])\n",
    "    else:\n",
    "        adata.obs['qc_mito_ok'] = True\n",
    "\n",
    "    # Combine QC flags\n",
    "    qc_pass = adata.obs[['qc_total_counts_ok', 'qc_ngenes_ok', 'qc_mito_ok']].all(axis=1)\n",
    "    adata.obs['qc_pass'] = qc_pass\n",
    "\n",
    "    # Filter to passing cells (optional: keep a copy of unfiltered as raw)\n",
    "    adata = adata[qc_pass].copy()\n",
    "\n",
    "    # Normalize, log1p, HVGs, scaling, PCA, neighbors, UMAP\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=3000)\n",
    "    adata = adata[:, adata.var['highly_variable']].copy()\n",
    "    sc.pp.scale(adata, max_value=10)\n",
    "    sc.tl.pca(adata, svd_solver='arpack')\n",
    "    sc.pp.neighbors(adata, n_neighbors=15, n_pcs=50)\n",
    "    sc.tl.umap(adata)\n",
    "\n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, merge replicates per region, annotate, preprocess, and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = {}\n",
    "output_dir = Path('scanpy') / 'processed'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for region, reps in regions.items():\n",
    "    adatas = []\n",
    "    for rep in reps:\n",
    "        fp = resolve_path(files[rep])\n",
    "        print(f'Reading {rep} from: {fp}')\n",
    "        adata = read_cellbender_h5(fp)\n",
    "        # Keep original counts in a layer for reference\n",
    "        adata.layers['counts'] = adata.X.copy()\n",
    "        # annotate region/replicate\n",
    "        adata = add_region_replicate_metadata(adata, region=region, replicate=rep)\n",
    "        # basic qc metrics (total_counts, n_genes_by_counts, pct_counts_mt)\n",
    "        annotate_basic_qc(adata)\n",
    "        adatas.append(adata)\n",
    "    # Concatenate replicates per region\n",
    "    adata_region = ad.concat(adatas, join='outer', label='batch', keys=reps, fill_value=0)\n",
    "    # Preprocess with adaptive QC suggestions\n",
    "    adata_proc = preprocess_one(adata_region, region=region)\n",
    "    preprocessed[region] = adata_proc\n",
    "    out_path = output_dir / f'{region}_preprocessed.h5ad'\n",
    "    print(f'Saving {region} to {out_path}')\n",
    "    adata_proc.write(out_path)\n",
    "\n",
    "# Optionally, also concatenate all regions into a single object and save\n",
    "all_adata = ad.concat(list(preprocessed.values()), join='outer', label='region', keys=list(preprocessed.keys()), fill_value=0)\n",
    "all_out = output_dir / 'all_regions_preprocessed.h5ad'\n",
    "print(f'Saving all regions to {all_out}')\n",
    "all_adata.write(all_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}